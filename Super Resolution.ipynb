{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":10871111,"sourceType":"datasetVersion","datasetId":6754014}],"dockerImageVersionId":30919,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport numpy as np\nimport glob\nimport cv2\nimport tensorflow as tf\nfrom tensorflow.keras.layers import Conv2D, BatchNormalization, LeakyReLU, PReLU, Dense, Flatten, UpSampling2D, Input, Add\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.losses import BinaryCrossentropy\nfrom tensorflow.keras.applications import VGG19\n\n# Check TensorFlow Version\nprint(f\"TensorFlow Version: {tf.__version__}\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Define dataset paths\nhigh_res_path = \"/kaggle/input/sardatadata/final data/image_chips_native\"\nlow_res_path = \"/kaggle/input/sardatadata/final data/low_immage\"\n\n# Function to Load Images\ndef load_images(path, img_size=(416, 416)):\n    image_paths = glob.glob(os.path.join(path, \"*.*\"))  # Accept all image types\n    print(f\"Found {len(image_paths)} images in {path}\")  # Debugging\n\n    images = []\n    for img_path in image_paths:\n        img = cv2.imread(img_path)\n        if img is None:\n            print(f\"Could not read {img_path}\")  # Debugging\n            continue\n        img = cv2.resize(img, img_size)\n        img = img / 255.0  # Normalize\n        images.append(img)\n\n    return np.array(images, dtype=np.float32)\n\n# Load High-Resolution and Low-Resolution Images\nhr_imgs = load_images(high_res_path, img_size=(416, 416))\nlr_imgs = load_images(low_res_path, img_size=(208, 208))  # Assuming 2× downsampling\n\n# Check loaded data\nprint(f\"Loaded {len(hr_imgs)} HR images and {len(lr_imgs)} LR images\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def build_generator():\n    inputs = Input(shape=(208, 208, 3))  # Low-resolution image input\n\n    # Initial Convolution Layer\n    x = Conv2D(64, kernel_size=9, padding=\"same\")(inputs)\n    x = PReLU(shared_axes=[1, 2])(x)\n\n    # Residual Blocks\n    def res_block(x):\n        res = Conv2D(64, kernel_size=3, padding=\"same\")(x)\n        res = BatchNormalization()(res)\n        res = PReLU(shared_axes=[1, 2])(res)\n        res = Conv2D(64, kernel_size=3, padding=\"same\")(res)\n        res = BatchNormalization()(res)\n        return Add()([x, res])\n\n    for _ in range(16):  # Use 16 Residual Blocks\n        x = res_block(x)\n\n    # Upsampling Layers\n    x = UpSampling2D(size=2)(x)\n    x = Conv2D(256, kernel_size=3, padding=\"same\")(x)\n    x = PReLU(shared_axes=[1, 2])(x)\n\n    x = UpSampling2D(size=2)(x)\n    x = Conv2D(256, kernel_size=3, padding=\"same\")(x)\n    x = PReLU(shared_axes=[1, 2])(x)\n\n    # Output Layer\n    outputs = Conv2D(3, kernel_size=9, padding=\"same\", activation=\"tanh\")(x)\n\n    return Model(inputs, outputs, name=\"Generator\")\n\ngenerator = build_generator()\ngenerator.summary()\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def build_discriminator():\n    inputs = Input(shape=(416, 416, 3))  # High-resolution image input\n\n    def d_block(x, filters, strides=1):\n        x = Conv2D(filters, kernel_size=3, strides=strides, padding=\"same\")(x)\n        x = BatchNormalization()(x)\n        x = LeakyReLU(alpha=0.2)(x)\n        return x\n\n    x = d_block(inputs, 64, strides=1)\n    x = d_block(x, 64, strides=2)\n    x = d_block(x, 128, strides=1)\n    x = d_block(x, 128, strides=2)\n    x = d_block(x, 256, strides=1)\n    x = d_block(x, 256, strides=2)\n    x = d_block(x, 512, strides=1)\n    x = d_block(x, 512, strides=2)\n\n    x = Flatten()(x)\n    x = Dense(1024)(x)\n    x = LeakyReLU(alpha=0.2)(x)\n    outputs = Dense(1, activation=\"sigmoid\")(x)\n\n    return Model(inputs, outputs, name=\"Discriminator\")\n\ndiscriminator = build_discriminator()\ndiscriminator.summary()\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"vgg = VGG19(weights=\"imagenet\", include_top=False, input_shape=(416, 416, 3))\nvgg = Model(inputs=vgg.input, outputs=vgg.get_layer(\"block5_conv4\").output)\nvgg.trainable = False\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Compile Models\ngenerator.compile(optimizer=Adam(1e-4), loss=\"mse\")\ndiscriminator.compile(optimizer=Adam(1e-4), loss=BinaryCrossentropy())\n\nbatch_size = 4\nepochs = 1\n\n# Training Loop\nfor epoch in range(epochs):\n    idx = np.random.randint(0, len(hr_imgs), batch_size)\n    lr_batch = lr_imgs[idx]\n    hr_batch = hr_imgs[idx]\n\n    # Generate fake HR images\n    fake_hr = generator.predict(lr_batch)\n\n    # Train Discriminator\n    d_loss_real = discriminator.train_on_batch(hr_batch, np.ones((batch_size, 1)))\n    d_loss_fake = discriminator.train_on_batch(fake_hr, np.zeros((batch_size, 1)))\n    d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n\n    # Train Generator (adversarial + perceptual loss)\n    g_loss = generator.train_on_batch(lr_batch, hr_batch)\n\n    if epoch % 100 == 0:\n        print(f\"Epoch {epoch}: D Loss: {d_loss}, G Loss: {g_loss}\")\n\n# Save the generator model\ngenerator.save(\"/kaggle/working/srgan_generator.h5\")\nprint(\"✅ Model saved successfully!\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import tensorflow as tf\nimport numpy as np\nfrom skimage.metrics import structural_similarity as ssim\n\ndef calculate_ssim(hr_real, hr_fake):\n    # Convert tensors to numpy arrays\n    hr_real_np = hr_real.numpy()\n    hr_fake_np = hr_fake.numpy()\n    \n    # Calculate SSIM for each image and take the mean\n    ssim_values = [ssim(hr_real_np[i], hr_fake_np[i], multichannel=True) for i in range(hr_real_np.shape[0])]\n    return np.mean(ssim_values)\n\n# Example usage inside training loop\nssim_score = calculate_ssim(hr_batch, fake_hr)\nprint(f'SSIM Score: {ssim_score}')\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Load the trained model\ngenerator = tf.keras.models.load_model(\"/kaggle/working/srgan_generator.h5\")\n\n# Load a test image and enhance resolution\ntest_img = cv2.imread(\"/kaggle/input/sardatadata/final data/low_immage/sample.jpg\")  # Change filename\ntest_img = cv2.resize(test_img, (208, 208))\ntest_img = np.expand_dims(test_img / 255.0, axis=0)\n\n# Generate High-Resolution Image\nsr_img = generator.predict(test_img)\nsr_img = np.clip(sr_img[0] * 255, 0, 255).astype(\"uint8\")\n\n# Save Output Image\ncv2.imwrite(\"/kaggle/working/super_resolved.jpg\", sr_img)\nprint(\"✅ Super-resolved image saved successfully!\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}